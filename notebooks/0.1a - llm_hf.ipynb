{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3827539c",
   "metadata": {},
   "source": [
    "# 00. Imports and env variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "23d2c975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain_community.llms import HuggingFacePipeline\n",
    "import torch\n",
    "from huggingface_hub import InferenceClient\n",
    "\n",
    "\n",
    "from pydantic import BaseModel\n",
    "from typing import List, Optional\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import json\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "96314817",
   "metadata": {},
   "outputs": [],
   "source": [
    "token = os.getenv(\"HF_TOKEN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328d0fe8",
   "metadata": {},
   "source": [
    "# 01. Problem Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "179d7827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parser classes\n",
    "\n",
    "# gaps\n",
    "class Gap(BaseModel):\n",
    "    title: str\n",
    "    description: str\n",
    "    impact: str\n",
    "    actions: List[str]\n",
    "\n",
    "class GapAnalysis(BaseModel):\n",
    "    company_name: str\n",
    "    job_title: str\n",
    "    generation_date: str\n",
    "    gaps: List[Gap]\n",
    "\n",
    "# resume\n",
    "class Header(BaseModel):\n",
    "    name: str\n",
    "    title: str\n",
    "    location: str\n",
    "    phone: str\n",
    "    email: str\n",
    "    linkedin: str\n",
    "    github: str\n",
    "    kaggle: Optional[str] = None\n",
    "\n",
    "Bullet = str\n",
    "\n",
    "class ProfessionalExperience(BaseModel):\n",
    "    company: str\n",
    "    period: str\n",
    "    role: str\n",
    "    location: str\n",
    "    bullets: List[Bullet]\n",
    "\n",
    "class Education(BaseModel):\n",
    "    institution: str\n",
    "    location: str\n",
    "    degree: str\n",
    "    period: str\n",
    "\n",
    "class Project(BaseModel):\n",
    "    name: str\n",
    "    year: str\n",
    "    context: str\n",
    "    bullets: List[Bullet]\n",
    "    github: Optional[str] = None\n",
    "\n",
    "class Activity(BaseModel):\n",
    "    organization: str\n",
    "    period: str\n",
    "    role: str\n",
    "    location: str\n",
    "\n",
    "class Certification(BaseModel):\n",
    "    name: str\n",
    "    issuer: str\n",
    "    year: str\n",
    "\n",
    "class SkillGroup(BaseModel):\n",
    "    label: str\n",
    "    entries: list[str]\n",
    "\n",
    "class SkillsSection(BaseModel):\n",
    "    groups: List[SkillGroup]\n",
    "\n",
    "class Resume(BaseModel):\n",
    "    header: Header\n",
    "    experience: List[ProfessionalExperience]\n",
    "    education: Optional[List[Education]] = None\n",
    "    projects: Optional[List[Project]] = None\n",
    "    activities: Optional[List[Activity]] = None\n",
    "    certifications: Optional[List[Certification]] = None\n",
    "    skills: Optional[SkillsSection] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "fdd6457f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gaps_schema = GapAnalysis.model_json_schema()\n",
    "\n",
    "resume_schema = Resume.model_json_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "41009c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model for inference\n",
    "\n",
    "client = InferenceClient(\n",
    "    model=\"Qwen/Qwen2.5-7B-Instruct\",\n",
    "    token=token  # ou via env\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "af4fd393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompts\n",
    "\n",
    "with open('./00_prompts/gaps.txt', 'r') as f:\n",
    "    gaps_prompt = f.read()\n",
    "\n",
    "with open('./00_prompts/resume.txt', 'r') as f:\n",
    "    resume_prompt = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "4eaf12dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# task prompt\n",
    "\n",
    "gaps_prompt_template = PromptTemplate(\n",
    "    input_variables=[\"job_description\", \"profile\"],\n",
    "    template=gaps_prompt\n",
    ")\n",
    "\n",
    "resume_prompt_template = PromptTemplate(\n",
    "    input_variables=[\"job_description\", \"profile\"],\n",
    "    template=resume_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "a4c08ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting descriptions\n",
    "\n",
    "with open('./01_jobs/job_1.txt', 'r') as f:\n",
    "    job_description = f.read()\n",
    "\n",
    "with open('./02_source/profile.txt', 'r') as f:\n",
    "    profile = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "0f19b120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt filling\n",
    "\n",
    "formatted_gaps_prompt = gaps_prompt_template.format(\n",
    "    job_description=job_description,\n",
    "    profile=profile,\n",
    "    schema=gaps_schema\n",
    ")\n",
    "\n",
    "formatted_resume_prompt = resume_prompt_template.format(\n",
    "    job_description=job_description,\n",
    "    profile=profile,\n",
    "    schema=resume_schema\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a91e72b",
   "metadata": {},
   "source": [
    "# 02. LLM execution and post processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "849e5c28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Voc√™ √© um especialista em RH e constru√ß√£o de curr√≠culos.\\n\\nTarefa:\\nAnalise a vaga e o perfil do candidato e gere um curr√≠culo com o maior match poss√≠vel usando as informa√ß√µes do candidato (mude a forma de escrita, mas n√£o omita nenhuma experiencia profissional ou forma√ß√£o academica).\\n\\nVaga:\\nDescri√ß√£o da vaga\\n\\nBuscamos profissional com especialidade em aplicar Intelig√™ncia Artificial Generativa para integrar nossa equipe de projetos voltados ao atendimento ao cliente. Como integrante do time, ser√° respons√°vel por desenvolver e implementar globalmente solu√ß√µes inovadoras utilizando principalmente tecnologias de IA generativa, contribuindo diretamente para otimizar nosso neg√≥cio e transformar a experi√™ncia do cliente atrav√©s de solu√ß√µes tecnol√≥gicas avan√ßadas.\\n\\nResponsabilidades e atribui√ß√µes\\n\\nDesenvolver de ponta a ponta solu√ß√µes de neg√≥cio utilizando tecnologias de IA generativa e aprendizado de m√°quina;\\nUtilizar ferramentas low/no-code como aceleradores do desenvolvimento e implementa√ß√£o de solu√ß√µes;\\nIdentificar e implementar solu√ß√µes t√©cnicas otimizadas para atender requisitos espec√≠ficos de projeto;\\nAnalisar sistematicamente oportunidades de melhoria cont√≠nua em sistemas j√° desenvolvidos;\\nMaximizar a escalabilidade, desempenho, usabilidade e confiabilidade dos aplicativos desenvolvidos;\\nDemonstrar iniciativa de aprendizado aut√¥nomo e atualiza√ß√£o constante sobre novas tecnologias emergentes;\\nParticipar ativamente dos eventos Scrum e garantir comprometimento com cronogramas e entregas acordadas;\\nElaborar documenta√ß√£o t√©cnica detalhada do projeto.\\n\\nRequisitos e qualifica√ß√µes\\n\\nExperi√™ncia profissional comprovada no desenvolvimento de chatbots, agentes de IA e sistemas aut√¥nomos utilizando modelos de linguagem avan√ßados;\\nProfici√™ncia em programa√ß√£o Python e bibliotecas relacionadas a IA/ML;\\nExperi√™ncia s√≥lida no desenvolvimento e implementa√ß√£o de APIs RESTful;\\nProfici√™ncia na linguagem SQL;\\nCompreens√£o dos fundamentos te√≥ricos dos modelos generativos de linguagem e suas aplica√ß√µes pr√°ticas;\\nConhecimento t√©cnico em Engenharia de Prompt;\\nExperi√™ncia com plataformas de computa√ß√£o em nuvem: Azure, Google Cloud ou AWS;\\nForma√ß√£o superior completa;\\nIngl√™s avan√ßado/fluente.\\n\\nDiferenciais:\\n\\nExperi√™ncia pr√°tica com Microsoft Power Platform, especialmente Copilot Studio, Power Apps e Power Automate;\\nDesenvolvimento de agentes de voz utilizando tecnologias de IA generativa;\\nExperi√™ncia em fine-tuning e contextualiza√ß√£o de modelos de linguagem para casos de uso espec√≠ficos;\\nFamiliaridade com Databricks e com ecossistema Azure (AI Foundry, AI services, Speech services, AI search e ML);\\nExperi√™ncia profissional no setor de Consumer Packaged Goods (CPG);\\nJ√° ter trabalhado sob a metodologia Agile e framework Scrum.\\n\\nInforma√ß√µes adicionais\\n\\nVale refei√ß√£o ou alimenta√ß√£o ifood;\\nVale transporte;\\nB√¥nus;\\nPlano de sa√∫de e Telemedicina;\\nConv√™nio odontol√≥gico;\\nConv√™nio Farm√°cia;\\nSeguro de vida;\\nInstituto Ambev de Previd√™ncia Privada;\\nAux√≠lio Material Escolar;\\nCesta de Natal e Kit Congelado;\\nBrinquedos de Natal;\\nEmpresa cidad√£ (licen√ßa maternidade e paternidade) e presente do beb√™;\\nDesconto mensal em produtos AMBEV;\\nBanco de horas;\\nWellhub (Gympass);\\nFretado;\\nAbono anual referente a um sal√°rio.\\n\\nOL√Å, SOMOS A AMBEV TECH! üíõüçªüíª\\n\\nIsso mesmo, o Hub de Tecnologia da Ambev!\\n\\nSomos respons√°veis por impulsionar a transforma√ß√£o digital da Ambev. O match perfeito entre o portf√≥lio da maior cervejaria do mundo e solu√ß√µes de Data & Analytics, Ciberseguran√ßa, Infraestrutura, Suporte, Field, Engenharia e Arquitetura de Software. Contamos com cerca de 50 Squads, que atuam em mais de 100 produtos, e cada linha de c√≥digo criada aqui conecta nossa paix√£o por tecnologia aos mais diversos brindes e suas raz√µes.\\n\\nDo campo ao copo, entregamos solu√ß√µes simples e escal√°veis usando tecnologia de ponta para transformar o dia a dia de milhares de pessoas. E isso s√≥ √© poss√≠vel gra√ßas a um time incr√≠vel que faz acontecer, com inova√ß√£o, senso de dono e muito orgulho de ser tech.\\n\\nPROTAGONIZAMOS SOLU√á√ïES GLOBAIS\\n\\nMuitas das nossas solu√ß√µes s√£o escaladas para a Ambev Global Tech, hub de tecnologia da Anheuser-Busch InBev (AB InBev), multinacional de bebidas e cervejas, e para outras unidades de neg√≥cio da companhia. Com escrit√≥rios espalhados por pa√≠ses como Estados Unidos, M√©xico, √çndia, Argentina e Brasil, estamos conectados a uma rede global de inova√ß√£o e tecnologia para transformar a Ambev em uma plataforma que conecta pessoas e o ecossistema.\\n\\nNOSSO JEITO TECH DE SER\\n\\nPor aqui, sonhamos grande e sabemos a import√¢ncia de ter equipes cada vez mais diversas. √â atrav√©s da pluralidade de ideias, experi√™ncias e opini√µes que conseguimos pensar fora da caixa e criar solu√ß√µes inovadoras. Por isso, contamos com nosso Comit√™ de Autenticidade Tech para olhar com muito carinho e responsabilidade todas as quest√µes relacionadas √† inclus√£o.\\n\\nQUER TRABALHAR COM A GENTE?\\n\\nPara atuar na Ambev Tech com projetos nacionais, temos unidades em Blumenau (SC), Maring√° (PR), S√£o Paulo (SP) e Jaguari√∫na (SP), e contamos tamb√©m com um time remoto em v√°rios cantos do Brasil e Am√©rica Latina. Atuamos com os modelos de trabalho remoto, h√≠brido e presencial, que ir√£o depender da especifica√ß√£o da vaga e de sua localidade, combinado?\\n\\nPara projetos internacionais, na Ambev Global Tech, a contrata√ß√£o acontece no modelo presencial, em Campinas (SP).\\n\\nQuer criar solu√ß√µes que v√£o do campo ao copo, do c√≥digo √† mesa do bar? Vem com a gente e confira todas as nossas oportunidades!\\n\\nWe‚Äôre here for tech and beer.\\n\\n\\n\\nPerfil do candidato:\\nFelipe Castro\\nData Scientist | Machine Learning | NLP | Applied AI\\nS√£o Paulo ‚Äì SP | (11) 93938-8082 | felmateos@alumni.usp.br | linkedin.com/in/felmateos | github.com/felmateos | kaggle.com/felmateos\\n\\nEXPERI√äNCIA PROFISSIONAL\\nIta√∫ Unibanco 2025 ‚Äì 2026\\nAnalista de Dados S√£o Paulo, SP\\n‚Ä¢ Desenvolvimento de modelo de Reconhecimento de Entidades Nomeadas (NER) com aprendizado supervisionado e fine-tuning de LLMs.\\n‚Ä¢ Aplica√ß√£o em textos corporativos para identifica√ß√£o autom√°tica de produtos e volumes, aumentando a rastreabilidade de ofertas.\\n‚Ä¢ Uso de Python, Transformers e PyTorch em ambiente produtivo.\\nIta√∫ Unibanco 2024 ‚Äì 2025\\nEstagi√°rio de Ci√™ncia de Dados S√£o Paulo, SP\\n‚Ä¢ Sistema de OCR com extra√ß√£o autom√°tica de entidades e valores em documentos estruturados e semiestruturados.\\n‚Ä¢ Uso de IA Generativa para substituir processos manuais, reduzindo tempo de processamento e aumentando efici√™ncia operacional.\\nUSP ‚Äì C4AI / IBM / FAPESP 2023 ‚Äì 2024\\nPesquisador Bolsista em Processamento de Linguagem Natural S√£o Paulo, SP\\n‚Ä¢ Inicia√ß√£o Cient√≠fica em classifica√ß√£o morfossint√°tica de textos sobre vacina√ß√£o contra COVID-19.\\n‚Ä¢ EDA, limpeza, rotula√ß√£o com ferramentas de PLN e an√°lise de distribui√ß√£o dos dados.\\n\\nFORMA√á√ÉO ACAD√äMICA\\nUniversidade de S√£o Paulo (USP) S√£o Paulo, SP\\nMestrado em Sistemas de Informa√ß√£o in√≠cio previsto Mar 2026\\nUniversidade de S√£o Paulo (USP) S√£o Paulo, SP\\nBacharelado em Sistemas de Informa√ß√£o 2020 ‚Äì 2024\\n\\nPROJETOS\\nPredi√ß√£o de Renda com Machine Learning 2025\\nProjeto de Ci√™ncia de Dados ‚Äì Kaggle\\n‚Ä¢ Pipeline de ML estruturado com Kedro para predi√ß√£o de renda anual.\\n‚Ä¢ Valida√ß√£o cruzada estratificada e avalia√ß√£o com F1-score e Precision-Recall para dados desbalanceados.\\n‚Ä¢ An√°lises estat√≠sticas e interpreta√ß√£o de vari√°veis para gera√ß√£o de insights socioecon√¥micos.\\n‚Ä¢ GitHub: github.com/felmateos/income-analysis\\nInternet Traffic Threat Classification 2025\\nProjeto de Ci√™ncia de Dados ‚Äì GitHub\\n‚Ä¢ Desenvolvimento de um sistema de classifica√ß√£o de amea√ßas em tr√°fego de rede criptografado usando Spiking Neural Networks (SNNs), inspirado em pesquisa acad√™mica recente (Neurocomputing, 2022).\\n‚Ä¢ Implementa√ß√£o de pipeline completo em PyTorch, incluindo processamento de PCAPs, extra√ß√£o de fluxos, rotula√ß√£o de ataques e tratamento de desbalanceamento com DBSCAN.\\n‚Ä¢ Otimiza√ß√£o de hiperpar√¢metros com Optuna e avalia√ß√£o com m√©tricas de precis√£o, revoca√ß√£o e acur√°cia, al√©m de an√°lise via matriz de confus√£o.\\n‚Ä¢ GitHub: github.com/felmateos/snn-darknet-traffic-classification\\n\\nATIVIDADES EXTRACURRICULARES\\nUSP ‚Äì Diret√≥rio Acad√™mico de Sistemas de Informa√ß√£o 2023\\nMonitor de Introdu√ß√£o √† Programa√ß√£o S√£o Paulo, SP\\nHYPE ‚Äì Ci√™ncia de Dados (Entidade Estudantil) 2022 ‚Äì 2024\\nDiretor de Gest√£o de Pessoas S√£o Paulo, SP\\n\\nCERTIFICA√á√ïES\\nCS50P ‚Äì Introduction to Programming with Python ‚Äî Harvard University (2024)\\nSQL for Data Science ‚Äî University of California, Davis (2024)\\nArtificial Intelligence Fundamentals ‚Äî IBM (2023)\\nData Science Foundations ‚Äî IBM (2023)\\n\\nCONHECIMENTOS\\nLinguagens: Python, SQL | Bibliotecas: Pandas, NumPy, scikit-learn, PyTorch, Transformers, TensorFlow\\nFerramentas: AWS, Git, DataBricks, Kedro, QuickSight | Metodologias: Scrum, CRISP-DM | Idiomas: Portugu√™s Nativo, Ingl√™s C1\\n\\nResponda APENAS com JSON v√°lido no seguinte formato:\\n{'$defs': {'Activity': {'properties': {'organization': {'title': 'Organization', 'type': 'string'}, 'period': {'title': 'Period', 'type': 'string'}, 'role': {'title': 'Role', 'type': 'string'}, 'location': {'title': 'Location', 'type': 'string'}}, 'required': ['organization', 'period', 'role', 'location'], 'title': 'Activity', 'type': 'object'}, 'Certification': {'properties': {'name': {'title': 'Name', 'type': 'string'}, 'issuer': {'title': 'Issuer', 'type': 'string'}, 'year': {'title': 'Year', 'type': 'string'}}, 'required': ['name', 'issuer', 'year'], 'title': 'Certification', 'type': 'object'}, 'Education': {'properties': {'institution': {'title': 'Institution', 'type': 'string'}, 'location': {'title': 'Location', 'type': 'string'}, 'degree': {'title': 'Degree', 'type': 'string'}, 'period': {'title': 'Period', 'type': 'string'}}, 'required': ['institution', 'location', 'degree', 'period'], 'title': 'Education', 'type': 'object'}, 'Header': {'properties': {'name': {'title': 'Name', 'type': 'string'}, 'title': {'title': 'Title', 'type': 'string'}, 'location': {'title': 'Location', 'type': 'string'}, 'phone': {'title': 'Phone', 'type': 'string'}, 'email': {'title': 'Email', 'type': 'string'}, 'linkedin': {'title': 'Linkedin', 'type': 'string'}, 'github': {'title': 'Github', 'type': 'string'}, 'kaggle': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'default': None, 'title': 'Kaggle'}}, 'required': ['name', 'title', 'location', 'phone', 'email', 'linkedin', 'github'], 'title': 'Header', 'type': 'object'}, 'ProfessionalExperience': {'properties': {'company': {'title': 'Company', 'type': 'string'}, 'period': {'title': 'Period', 'type': 'string'}, 'role': {'title': 'Role', 'type': 'string'}, 'location': {'title': 'Location', 'type': 'string'}, 'bullets': {'items': {'type': 'string'}, 'title': 'Bullets', 'type': 'array'}}, 'required': ['company', 'period', 'role', 'location', 'bullets'], 'title': 'ProfessionalExperience', 'type': 'object'}, 'Project': {'properties': {'name': {'title': 'Name', 'type': 'string'}, 'year': {'title': 'Year', 'type': 'string'}, 'context': {'title': 'Context', 'type': 'string'}, 'bullets': {'items': {'type': 'string'}, 'title': 'Bullets', 'type': 'array'}, 'github': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'default': None, 'title': 'Github'}}, 'required': ['name', 'year', 'context', 'bullets'], 'title': 'Project', 'type': 'object'}, 'SkillGroup': {'properties': {'label': {'title': 'Label', 'type': 'string'}, 'entries': {'items': {'type': 'string'}, 'title': 'Entries', 'type': 'array'}}, 'required': ['label', 'entries'], 'title': 'SkillGroup', 'type': 'object'}, 'SkillsSection': {'properties': {'groups': {'items': {'$ref': '#/$defs/SkillGroup'}, 'title': 'Groups', 'type': 'array'}}, 'required': ['groups'], 'title': 'SkillsSection', 'type': 'object'}}, 'properties': {'header': {'$ref': '#/$defs/Header'}, 'experience': {'items': {'$ref': '#/$defs/ProfessionalExperience'}, 'title': 'Experience', 'type': 'array'}, 'education': {'anyOf': [{'items': {'$ref': '#/$defs/Education'}, 'type': 'array'}, {'type': 'null'}], 'default': None, 'title': 'Education'}, 'projects': {'anyOf': [{'items': {'$ref': '#/$defs/Project'}, 'type': 'array'}, {'type': 'null'}], 'default': None, 'title': 'Projects'}, 'activities': {'anyOf': [{'items': {'$ref': '#/$defs/Activity'}, 'type': 'array'}, {'type': 'null'}], 'default': None, 'title': 'Activities'}, 'certifications': {'anyOf': [{'items': {'$ref': '#/$defs/Certification'}, 'type': 'array'}, {'type': 'null'}], 'default': None, 'title': 'Certifications'}, 'skills': {'anyOf': [{'$ref': '#/$defs/SkillsSection'}, {'type': 'null'}], 'default': None}}, 'required': ['header', 'experience'], 'title': 'Resume', 'type': 'object'}\\n\\nN√£o inclua texto fora do JSON.\""
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_resume_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "c141acca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output generation and parsing\n",
    "\n",
    "gaps_output = client.chat_completion(messages=[{\"role\": \"user\", \"content\": formatted_gaps_prompt}])\n",
    "gaps_parsed = GapAnalysis.model_validate_json(gaps_output.choices[0].message.content)\n",
    "gaps = gaps_parsed.model_dump(mode=\"python\")\n",
    "\n",
    "resume_output = client.chat_completion(messages=[{\"role\": \"user\", \"content\": formatted_resume_prompt}])\n",
    "resume_parsed = Resume.model_validate_json(resume_output.choices[0].message.content)\n",
    "resume = resume_parsed.model_dump(mode=\"python\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e138469",
   "metadata": {},
   "source": [
    "# 03. Storing output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "5607eebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing output\n",
    "\n",
    "with open('./03_jsons/gap_analysis.json', 'w') as f:\n",
    "    json.dump(gaps, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "with open('./03_jsons/resume.json', 'w') as f:\n",
    "    json.dump(resume, f, indent=2, ensure_ascii=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
